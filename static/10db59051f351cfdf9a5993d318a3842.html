
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="笔记">
    <meta name="keywords" content="hdfs,flink">
    <title>hadoop HDFS作为Flink 的 Sink</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <style>
        :root {
            --day-bg: #ffffff;
            --day-text: #333333;
            --night-bg: #1a1a1a;
            --night-text: #f0f0f0;
        }

        body {
            max-width: 820px;
            margin: 0 auto;
            padding: 20px;
            line-height: 21px;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Arial, sans-serif;
            transition: background-color 0.3s, color 0.3s;
        }

        .metadata {
            margin-bottom: 30px;
            padding: 15px;
            background: rgba(0, 0, 0, 0.05);
            border-radius: 5px;
        }

        .metadata p {
            margin: 5px 0;
            font-size: 0.9em;
        }

        .day-mode {
            background-color: var(--day-bg);
            color: var(--day-text);
        }

        .night-mode {
            background-color: var(--night-bg);
            color: var(--night-text);
        }

        h1 { font-size: 19px; text-align: center; }
        h2 { font-size: 18px; }
        h3 { font-size: 16px; }
        h4 { font-size: 14px; }
        h5 { font-size: 12px; }
        h6 { font-size: 11px; }

        pre {
            line-height: 24px;
            padding: 15px;
            border-radius: 5px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            overflow-x: auto;
        }

        code {
            font-family: 'Fira Code', Consolas, Monaco, 'Courier New', monospace;
        }

        img {
            display: block;
            max-width: 600px;
            height: auto;
            margin: 20px auto;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .content {
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            padding: 20px;
            border-radius: 8px;
            background-color: rgba(255, 255, 255, 0.05);
        }

        footer {
            text-align: center;
            margin-top: 40px;
            padding: 20px;
            border-top: 1px solid #ddd;
            font-size: 0.9em;
        }

        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        .content {
            animation: fadeIn 0.5s ease-in;
        }
    </style>
</head>
<body class="day-mode">
    <div class="metadata">
        <p><strong>Title:</strong> hadoop HDFS作为Flink 的 Sink</p>
        <p><strong>Categories:</strong> shell,hadoop,hdfs</p>
        <p><strong>Description:</strong> 笔记</p>
        <p><strong>Keywords:</strong> hdfs,flink</p>
    </div>
    <div class="content">
        <p>因工作需求，学习了Hdfs分布式文件存储系统，所整合Flink + HDFS 作为一个Demo 帮助大家跳坑。
HDFS 采用NS高可用模式。</p>
<h1 id="hdfsmanagerjava">HDFSManager.Java</h1>
<pre class="codehilite"><code>* 初始化HDFS链接。
</code></pre>

<pre class="codehilite"><code class="language-java">package com.e.firsh.spb.utils.hdfs;

import com.alibaba.fastjson.JSONObject;
import com.e.firsh.base.esb.BO;
import com.e.firsh.base.utils.Registry;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import java.io.IOException;
import java.util.Set;

/**
 * The type Hdfs manager.
 */
public class HDFSManager {
    private static Logger logger = LoggerFactory.getLogger(HDFSManager.class);
    private static Configuration configuration;
    private static FileSystem fs;

    public HDFSManager() {
        JSONObject jsonObject = new JSONObject();
        jsonObject.put(&quot;fs.defaultFS&quot;, &quot;hdfs://ns&quot;);
        jsonObject.put(&quot;dfs.nameservices&quot;, &quot;ns&quot;);
        jsonObject.put(&quot;dfs.ha.namenodes.ns&quot;,&quot;nn1,nn2&quot;);
        jsonObject.put(&quot;dfs.namenode.rpc-address.ns.nn1&quot;, &quot;10.11.0.12:9000&quot;);
        jsonObject.put(&quot;dfs.namenode.rpc-address.ns.nn2&quot;, &quot;10.11.0.13:9000&quot;);
        jsonObject.put(&quot;dfs.client.failover.proxy.provider.ns&quot;, &quot;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&quot;);
        init(jsonObject);
    }

    public boolean init(JSONObject args) {
        Configuration conf = new Configuration();
        Set&lt;String&gt; itr = args.keySet();
        if (itr != null) {
            for (String pname : itr) {
                String pvalue = args.getString(pname);
                conf.set(pname, pvalue);
            }
        }
        try {
            fs = FileSystem.get(conf);
            return true;
        } catch (Exception e) {
            logger.error(e.getMessage() + &quot;:{}&quot;, e);
        }
        return false;
    }


    public BO appendToFile(String destPath, String line) throws IOException {
        BO respBO = BO.createResponseBO();
        Path path = new Path(destPath);
        FSDataOutputStream dos = null;
        try {
            if (!fs.exists(path)) {
                dos = fs.create(path);
            } else {
                dos = fs.append(path);
            }
            byte[] readBuf = line.getBytes(&quot;UTF-8&quot;);
            dos.write(readBuf, 0, readBuf.length);
            dos.close();
            respBO.setDataNameValue(&quot;length&quot;, readBuf.length);
        } catch (Exception e) {
            logger.error(e.getMessage() + &quot;:{}&quot;, e);
            respBO.setCompleteCode(BO.BO_V_CC_FAILED);
        } finally {
            if (dos != null) {
                dos.close();
            }
        }
        return respBO;
    }

    public static void main(String[] args) {
        HDFSManager hdfsManager = new HDFSManager();
        try {
            hdfsManager.appendToFile(&quot;/testmq&quot;,&quot;hello w&quot;);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public static void init2(){
         configuration = new Configuration();
        /**TODO 添加Hadoop配置内容*/
        configuration.set(&quot;dfs.namenode.name.dir&quot;, &quot;file:///home/admin/data/hadoop/hdfs/name&quot;);
        configuration.set(&quot;dfs.nameservices&quot;, &quot;ns&quot;);
        configuration.set(&quot;dfs.ha.namenodes.ns&quot;, &quot;nn1,nn2&quot;);
        configuration.set(&quot;dfs.namenode.rpc-address.ns.nn1&quot;, &quot;10.11.0.12:9000&quot;);
        configuration.set(&quot;dfs.namenode.rpc-address.ns.nn2&quot;, &quot;10.11.0.13:9000&quot;);
        configuration.set(&quot;dfs.namenode.shared.edits.dir&quot;, &quot;qjournal://10.11.0.12:8485;10.11.0.13:8485;10.11.0.14:8485/ns&quot;);
        configuration.set(&quot;hadoop.tmp.dir&quot;, &quot;/home/admin/data/hadoop/tmp&quot;);
        configuration.set(&quot;fs.defaultFS&quot;, &quot;hdfs://ns&quot;);
        configuration.set(&quot;dfs.journalnode.edits.dir&quot;, &quot;/home/admin/data/hadoop/journal&quot;);
        configuration.set(&quot;dfs.client.failover.proxy.provider.ns&quot;, &quot;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&quot;);
        configuration.set(&quot;ha.zookeeper.quorum&quot;, &quot;10.11.0.12:2181,10.11.0.13:2181,10.11.0.14:2181&quot;);
        configuration.set(&quot;mapreduce.input.fileinputformat.split.minsize&quot;, &quot;10&quot;);


        try {
            fs = FileSystem.get(configuration);
        } catch (Exception e) {
            logger.error(e.getMessage() + &quot;:{}&quot;, e);
        }
    }
}
</code></pre>

<h1 id="hdfssinkjava">HDFSSink.Java</h1>
<ul>
<li>继承<code>RichSinkFunction</code>，重写<code>open</code> 和 <code>invoke</code>方法，还有<code>close</code>。</li>
</ul>
<pre class="codehilite"><code class="language-java">package com.e.firsh.spb.sink;

import com.e.firsh.spb.utils.hdfs.HDFSManager;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;

/**
 * Created by zhangjianxin on 2017/8/1.
 */
public class HDFSSink extends RichSinkFunction&lt;String&gt; {
    private HDFSManager hdfsManager;
    private final static  String  HDFS_PATH =&quot;/testmq&quot;;
    @Override
    public void invoke(String t) throws Exception {
        hdfsManager.appendToFile(HDFS_PATH,t);
    }
    @Override
    public void open(Configuration config) {
        hdfsManager = new HDFSManager();
    }
}
</code></pre>

<h1 id="flinkhdfs">以上代码为简易版经过修改，思路清晰，（Flink自带一种HDFS的链接方式详情见链接：）</h1>
<ul>
<li>https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/filesystem_sink.html</li>
</ul>
    </div>
    <footer>
        Power By Python Markdown Generate 2024-11-11 11:39:19
    </footer>
    <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            document.querySelectorAll('pre code').forEach((block) => {
                hljs.highlightBlock(block);
            });
        });

        function setThemeMode() {
            const hour = new Date().getHours();
            const body = document.body;
            if (hour >= 18 || hour < 6) {
                body.classList.remove('day-mode');
                body.classList.add('night-mode');
            } else {
                body.classList.remove('night-mode');
                body.classList.add('day-mode');
            }
        }

        setThemeMode();
        setInterval(setThemeMode, 60000);
    </script>
</body>
</html>
