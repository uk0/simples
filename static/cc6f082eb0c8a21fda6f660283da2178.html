<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<title>Hadoop集群配置HA。</title>
<meta name="description" content="Hadoop集群配置zookeeper HA" />
<meta name="keywords" content="Hadoop, zookeeper" />
<style>
body {
  font-family: sans-serif;
  line-height: 21px;
  background-color: #222;
  color: #eee;
  margin: 0;
  padding: 0;
  max-width: 820px;
  margin: 0 auto;
  box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3);
}
h1 {
  font-size: 20px;
}
h2 {
  font-size: 18px;
}
h3 {
  font-size: 16px;
}
h4 {
  font-size: 14px;
}
h5 {
  font-size: 12px;
}
h6 {
  font-size: 11px;
}
pre {
  line-height: 24px;
  background-color: #333;
  padding: 10px;
  margin: 10px 0;
  overflow-x: auto;
}
code {
  background-color: #444;
  color: #eee;
  padding: 2px 4px;
  border-radius: 4px;
  font-family: monospace;
}
img {
  display: block;
  margin: 0 auto;
  width: 600px;
  height: 375px;
}
footer {
  text-align: center;
  padding: 10px 0;
  font-size: 12px;
}
.highlight {
  background-color: #444;
  color: #eee;
}
</style>
<script>
window.onload = function() {
  var now = new Date();
  var hour = now.getHours();
  var body = document.getElementsByTagName("body")[0];
  if (hour >= 19 || hour < 6) {
    body.style.backgroundColor = "#111";
  }
  var codeElements = document.querySelectorAll('pre code');
  for (var i = 0; i < codeElements.length; i++) {
    codeElements[i].classList.add("highlight");
  }
};
</script>
</head>
<body>
<h1>Hadoop集群配置HA</h1>

<h2>准备</h2>

<ul>
<li>JDK1.8</li>
<li>NTP</li>
<li>zookeeper</li>
<li>NTPDATE</li>
<li>配置目录</li>
</ul>

<pre><code>scp -r zookeeper/ dscn$:/home/zookeeper

scp -r hadoop/ dscn$:/home/hadoop

mkdir  -p /home/program/hadoop/  data logs pids  # hadoop 文件路径

mkdir  -p  /home/program/zookeeper data logs pids # zookeeper 文件

</code></pre>

<pre><code>hdfs haadmin -transitionToActive nn1 --forcemanual
解决启动节点都为 `standby`

</code></pre>

<h2>环境变量 Hadoop</h2>

<pre><code>  echo "
        export JAVA_HOME=/usr/java/jdk1.8.0_73
        export HADOOP_HOME=/home/dscs/hadoop
        export HADOOP_LOG_DIR=/home/program/hadoop/logs
        export HADOOP_PID_DIR=/home/program/hadoop/pids
        export HADOOP_IDENT_STRING=dscs
        export YARN_LOG_DIR=/home/program/hadoop/logs
        export YARN_PID_DIR=/home/program/hadoop/pids
        export YARN_IDENT_STRING=dscs
        export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
        PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$JAVA_HOME/bin:$PATH
        " >>~/.bash_profile
    source ~/.bash_profile
</code></pre>

<h2>环境变量 Java</h2>

<pre><code>    export JAVA_HOME=$(dirname $(dirname $(readlink -f $(which javac))))
</code></pre>

<h2>zookeeper config</h2>

<pre><code>

    dataDir=/usr/local/program/zookeeper/data
    dataLogDir=/usr/local/program/zookeeper/logs
    clientPort=2181
    tickTime=2000
    initLimit=5
    syncLimit=2
    server.1=dscn1:2888:3888
    server.2=dscn2:2888:3888
    server.3=dscn3:2888:3888

</code></pre>

<pre><code>    for i in 1 2 3
    do 

        ssh dscn$i mkdir -p /home/program/zookeeper/data/ echo $i > /home/program/zookeeper/data/myid

    done 
</code></pre>

<h2>hadoop 启动流程</h2>

<ul>
<li>启动 zookeeper (3个节点)
<pre><code>
            ./zkServer.sh start ../conf/zoo.cfg
        </code></pre></li>
<li>启动 JournalNode (3个节点)
<pre><code>
            sbin/hadoop-daemon.sh start journalnode
        </code></pre></li>
<li>在其中一个namenode上格式化：
<pre><code>
             bin/hdfs namenode -format -bjsxt 
        </code></pre></li>
<li>启动刚刚格式化的namenode:
<pre><code>
            sbin/hadoop-daemon.sh start namenode
        </code></pre></li>
<li>在另一个没有格式化的namenode上执行
<pre><code>
            bin/hdfs namenode -bootstrapStandby 
            
      </code></pre></li>
<li>启动第二个namenode
<pre><code>
         sbin/hadoop-daemon.sh start namenode
     </code></pre></li>
<li>启动第二个datanode(3个节点)
<pre><code>
         sbin/hadoop-daemon.sh start datanode
     </code></pre></li>
<li>在其中一个namenode上初始化zkfc：
<pre><code>
        bin/hdfs zkfc -formatZK
    </code></pre></li>
<li>启动 JobHistory
<pre><code>
    sbin/mr-jobhistory-daemon.sh start historyserver
  </code></pre></li>
</ul>

<h2>异常描述</h2>

<ul>
<li>Hadoop2.0的HA机制判断两者元数据不一致时，为了防止脑裂，所以使两者都处于standby状态,
<li>场景：两台namenode都是standby。
<li>zk集群里只是保存，hadoop集群的ha状态，而不保存数据，所以在ha机制出现问题时，可以使用此条命令：
<li>停止集群 hadoop
<pre><code>
        hdfs zkfc -formatZK
  </code></pre></li>
</ul>

<h2>插曲 scp 发现存储不够了</h2>

<pre><code>

 [root@dscn1 hadoop]# vgs
  VG   #PV #LV #SN Attr   VSize    VFree
  VG00   1  10   0 wz--n- <199.51g <1.26g


  lvextend -L +173G /dev/mapper/VG00-lvroot


  xfs_growfs /dev/mapper/VG00-lvroot

 </code></pre>

<h2>读取文件里面的文件路径参数【转译】</h2>

<pre><code>

HBASE_TMP_DIR=$(cat $HBASE_PACKAGE_PATH/config | grep HBASE_TMP_DIR | awk -F "=" '{print$2}')

HBASE_TMP_DIR_STR=$(echo $HBASE_TMP_DIR | sed 's#\/#\\\/#g')

sed -i "s/HBASE_TMP_DIR/$HBASE_TMP_DIR_STR/" $HBASE_HOME/conf/hbase-site.xml

</code></pre>

<h2>读取节点配置合理配置主从节点</h2>

<pre><code>
OLD_IFS="$IFS"
IFS=","
arr=($HBASE_REGION)
IFS="$OLD_IFS"
for s in ${arr[@]}
do
    echo "$s" >>$HBASE_HOME/conf/regionservers
done

</code></pre>
<footer>
Power By Gemini TextGenerate 2024-09-17 00:49:15
</footer>
</body>
</html>